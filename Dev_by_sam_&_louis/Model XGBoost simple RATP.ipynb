{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from skrub import TableVectorizer\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import holidays\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "import datetime\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the files\n",
    "#df_train = pd.read_parquet(\"/Users/louisleibovici/Documents/VS_Code/Bike_counters DSB Project/bike_counters/data/train.parquet\")\n",
    "#df_test = pd.read_parquet(\"/Users/louisleibovici/Documents/VS_Code/Bike_counters DSB Project/bike_counters/data/final_test.parquet\")\n",
    "\n",
    "df_train = pd.read_parquet(\"/Users/srazjman/Python/bike_counters/data/train.parquet\")\n",
    "df_test = pd.read_parquet(\"/Users/srazjman/Python/bike_counters/data/final_test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add jour ferie data\n",
    "jour_feries = (\n",
    "    pd.read_csv(\n",
    "        #\"/Users/louisleibovici/Documents/VS_Code/Bike_counters DSB Project/bike_counters/external_data/jours_feries_metropole.csv\",\n",
    "        \"/Users/srazjman/Python/bike_counters/external_data/jours_feries_metropole.csv\",\n",
    "        date_format=\"%Y%m%d%H\"  # Ensure date format is handled correctly\n",
    "    )\n",
    "    .drop(columns=[\"annee\", \"zone\"])  # Drop unnecessary columns\n",
    ")\n",
    "\n",
    "# Convert 'date' column to datetime\n",
    "jour_feries['date'] = pd.to_datetime(jour_feries['date'])\n",
    "\n",
    "# Filter rows based on the date range of df_train and df_test\n",
    "jour_feries = jour_feries[\n",
    "    (jour_feries[\"date\"] >= df_train[\"date\"].min() - datetime.timedelta(hours=1))\n",
    "    & (jour_feries[\"date\"] <= df_test[\"date\"].max() + datetime.timedelta(hours=1))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add mouvements sociaux data :\n",
    "mouvements_sociaux = (\n",
    "    pd.read_csv(\n",
    "        #\"/Users/louisleibovici/Documents/VS_Code/Bike_counters DSB Project/bike_counters/external_data/mouvements-sociaux-depuis-2002.csv\",\n",
    "         \"/Users/srazjman/Python/bike_counters/external_data/mouvements-sociaux-depuis-2002.csv\",\n",
    "        date_format=\"%Y%m%d%H\",\n",
    "        sep=\";\"\n",
    "    )\n",
    "    .drop(columns=['date_de_fin', 'Organisations syndicales', 'Métiers ciblés par le préavis',\n",
    "                   'Population devant travailler ciblee par le préavis', 'Nombre de grévistes du préavis'])  # Drop unnecessary columns\n",
    ")\n",
    "\n",
    "mouvements_sociaux['Date'] = pd.to_datetime(mouvements_sociaux['Date'])\n",
    "\n",
    "mouvements_sociaux = mouvements_sociaux[\n",
    "    (mouvements_sociaux[\"Date\"] >= df_train[\"date\"].min() - datetime.timedelta(hours=1))\n",
    "    & (mouvements_sociaux[\"Date\"] <= df_test[\"date\"].max() + datetime.timedelta(hours=1))\n",
    "]\n",
    "\n",
    "mouvements_sociaux = mouvements_sociaux[mouvements_sociaux['Date'] != pd.Timestamp('2021-03-08')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z5/dkd4bk6j6bvdrckls61_jsc00000gp/T/ipykernel_63503/1833608414.py:35: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  arrets_count = gdf_arrets_in_buffer.groupby('counter_id').size()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              coordinates  arrets_count\n",
      "48321  48.846028,2.375429           100\n",
      "48324  48.846028,2.375429           100\n",
      "48327  48.846028,2.375429           100\n",
      "48330  48.846028,2.375429           100\n",
      "48333  48.846028,2.375429           100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z5/dkd4bk6j6bvdrckls61_jsc00000gp/T/ipykernel_63503/1833608414.py:35: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  arrets_count = gdf_arrets_in_buffer.groupby('counter_id').size()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          coordinates  arrets_count\n",
      "0  48.846028,2.375429           100\n",
      "1  48.846028,2.375429           100\n",
      "2  48.846028,2.375429           100\n",
      "3  48.846028,2.375429           100\n",
      "4  48.846028,2.375429           100\n"
     ]
    }
   ],
   "source": [
    "#Add list of Ratp Stop :\n",
    "arrets_ratp = (\n",
    "    pd.read_csv(\n",
    "    #\"/Users/louisleibovici/Documents/VS_Code/Bike_counters DSB Project/bike_counters/external_data/arrets.csv\",\n",
    "    \"/Users/srazjman/Python/bike_counters/external_data/arrets.csv\",\n",
    "    sep=\";\"\n",
    "    ).drop(columns=['ArRId', 'ArRVersion', 'ArRCreated', 'ArRChanged', 'ArRName', 'ArRType', \n",
    "                    'ArRXEpsg2154', 'ArRYEpsg2154', 'ArRTown', 'ArRPostalRegion', 'ArRAccessibility',\n",
    "                      'ArRAudibleSignals', 'ArRVisualSigns', 'ArRFareZone', 'ZdAId'])\t\n",
    ")\n",
    "arrets_ratp.head()\n",
    "\n",
    "for df in [df_train, df_test]:\n",
    "\n",
    "    df['geometry'] = df['coordinates'].apply(\n",
    "        lambda coord: Point(map(float, coord.split(',')))\n",
    "    )\n",
    "    gdf_bike = gpd.GeoDataFrame(df, geometry='geometry', crs=\"EPSG:4326\")\n",
    "    arrets_ratp['geometry'] = arrets_ratp['ArRGeopoint'].apply(\n",
    "        lambda coord: Point(map(float, coord.split(',')))\n",
    "    )\n",
    "    gdf_arrets = gpd.GeoDataFrame(arrets_ratp, geometry='geometry', crs=\"EPSG:4326\")\n",
    "    #2:\n",
    "    gdf_bike = gdf_bike.to_crs(\"EPSG:3857\")\n",
    "    gdf_arrets = gdf_arrets.to_crs(\"EPSG:3857\")\n",
    "    #3: \n",
    "    gdf_bike['buffer_950m'] = gdf_bike['geometry'].buffer(950)\n",
    "    #4:\n",
    "    gdf_arrets_in_buffer = gpd.sjoin(\n",
    "        gdf_arrets,\n",
    "        gdf_bike.set_geometry('buffer_950m'),\n",
    "        predicate='within'\n",
    "    )\n",
    "    gdf_arrets_in_buffer = gdf_arrets_in_buffer[['counter_id', 'geometry']].drop_duplicates()\n",
    "    arrets_count = gdf_arrets_in_buffer.groupby('counter_id').size()\n",
    "    df['arrets_count'] = df['counter_id'].map(arrets_count).fillna(0)\n",
    "    print(df[['coordinates', 'arrets_count']].head())\n",
    "    df = df.drop(columns=['geometry'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the date feature on different time scales :\n",
    "\n",
    "fr_holidays = holidays.France()\n",
    "\n",
    "def _encode_dates(X):\n",
    "    X = X.copy()  # modify a copy of X\n",
    "    # Encode the date information from the DateOfDeparture columns\n",
    "    X[\"year\"] = X[\"date\"].dt.year\n",
    "    X[\"month\"] = X[\"date\"].dt.month\n",
    "    X[\"day\"] = X[\"date\"].dt.day\n",
    "    X[\"weekday\"] = X[\"date\"].dt.weekday\n",
    "    X[\"hour\"] = X[\"date\"].dt.hour\n",
    "\n",
    "    # creation of a binary varible depicting if day in weekend\n",
    "    X[\"is_weekend\"] = np.where(X[\"weekday\"] + 1 > 5, 1, 0)\n",
    "\n",
    "    # Add a feature to indicate if the day is a holiday in France\n",
    "    X[\"is_holiday\"] = X[\"date\"].apply(lambda d: 1 if d in fr_holidays else 0)\n",
    "\n",
    "    # and if it is a jour ferie in France :\n",
    "    X[\"is_jour_ferie\"] = X[\"date\"].dt.date.isin(jour_feries['date']).astype(int)\n",
    "\n",
    "    # and it is a jour of \"mouvement social\" in France :\n",
    "    X[\"is_jour_mouvement_social\"] = X[\"date\"].dt.date.isin(mouvements_sociaux['Date']).astype(int)\n",
    "\n",
    "    # Finally we can drop the original columns from the dataframe\n",
    "    return X.drop(columns=[\"date\"])\n",
    "\n",
    "df_train = _encode_dates(df_train)\n",
    "df_test = _encode_dates(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing :\n",
    "\n",
    "# Drop unnecessary columns :\n",
    "# df_train = df_train.drop(columns=[\"coordinates\", \"counter_name\", \"site_name\", \"counter_technical_id\"])\n",
    "# df_test = df_test.drop(columns=[\"coordinates\", \"counter_name\", \"site_name\", \"counter_technical_id\"])\n",
    "\n",
    "# Extract features from counter_installation_date\n",
    "for df in [df_train, df_test]:\n",
    "    df[\"installation_year\"] = df[\"counter_installation_date\"].dt.year\n",
    "    df[\"installation_month\"] = df[\"counter_installation_date\"].dt.month\n",
    "\n",
    "df_train = df_train.drop(columns=[\"counter_installation_date\"])\n",
    "df_test = df_test.drop(columns=[\"counter_installation_date\"])\n",
    "\n",
    "# Label encode high-cardinality categorical features\n",
    "label_encoders = {}\n",
    "for col in [\"counter_id\", \"site_id\", \"counter_name\", \"site_name\", \"counter_technical_id\", \"coordinates\"]:\n",
    "    le = LabelEncoder()\n",
    "    df_train[col] = le.fit_transform(df_train[col])\n",
    "    df_test[col] = le.fit_transform(df_test[col])\n",
    "    label_encoders[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['counter_id', 'counter_name', 'site_id', 'site_name', 'bike_count',\n",
       "       'coordinates', 'counter_technical_id', 'latitude', 'longitude',\n",
       "       'log_bike_count', 'arrets_count', 'year', 'month', 'day', 'weekday',\n",
       "       'hour', 'is_weekend', 'is_holiday', 'is_jour_ferie',\n",
       "       'is_jour_mouvement_social', 'installation_year', 'installation_month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train.drop(columns = 'geometry')\n",
    "df_test = df_test.drop(columns = 'geometry')\n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=[\"bike_count\", \"log_bike_count\"])\n",
    "y_train = df_train[\"log_bike_count\"]\n",
    "\n",
    "X_test = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the XGBoost model\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "\n",
    "# Define the parameter grid for tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [90,100,110],#100\n",
    "    'learning_rate': [0.08, 0.1,0.15],#0.1\n",
    "    'max_depth': [11, 12, 14],#12\n",
    "    'subsample': [0.5, 0.6],#0.6\n",
    "    'colsample_bytree': [0.5, 0.6, 0.7],#0.6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best Parameters: {'subsample': 0.6, 'n_estimators': 100, 'max_depth': 12, 'learning_rate': 0.1, 'colsample_bytree': 0.6}\n",
      "Best Score: 0.907761178990745\n"
     ]
    }
   ],
   "source": [
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=50,  # Number of parameter settings sampled\n",
    "    scoring='neg_mean_squared_error',  # Use appropriate scoring metric\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Use all available processors\n",
    ")\n",
    "\n",
    "# Perform the search\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and score\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best Score:\", -random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the model with the best parameters\n",
    "best_xgb_model = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Preprocessing pipeline\\npipeline = Pipeline(\\n    steps=[\\n        ('preprocessor', TableVectorizer()),\\n        ('model', best_xgb_model),\\n    ]\\n)\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Preprocessing pipeline\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', TableVectorizer()),\n",
    "        ('model', best_xgb_model),\n",
    "    ]\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the XGBoost regressor\n",
    "model = best_xgb_model\n",
    "\n",
    "# Fit the model\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    ")\n",
    "\n",
    "# Make Predictions on Test Data\n",
    "y_predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26157886 1.5956918  2.1115322  ... 5.2928267  4.823097   3.854876  ]\n"
     ]
    }
   ],
   "source": [
    "print(y_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(y_predictions, columns=[\"log_bike_count\"]).reset_index().rename(\n",
    "#    columns={\"index\": \"Id\"}\n",
    "#).to_csv(\"/Users/louisleibovici/Documents/VS_Code/Bike_counters DSB Project/bike_counters/predictions_option_2_vsimple.csv\", index=False)\n",
    "pd.DataFrame(y_predictions, columns=[\"log_bike_count\"]).reset_index().rename(\n",
    "    columns={\"index\": \"Id\"}\n",
    ").to_csv(\"/Users/srazjman/Python/bike_counters/predictions_option_2_vsimple_Ratp.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
