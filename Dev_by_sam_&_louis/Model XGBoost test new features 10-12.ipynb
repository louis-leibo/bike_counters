{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from skrub import TableVectorizer\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import holidays\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the files\n",
    "df_train = pd.read_parquet(\"/Users/louisleibovici/Documents/VS_Code/Bike_counters DSB Project/bike_counters/data/train.parquet\")\n",
    "df_test = pd.read_parquet(\"/Users/louisleibovici/Documents/VS_Code/Bike_counters DSB Project/bike_counters/data/final_test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add jour ferie data\n",
    "jour_feries = (\n",
    "    pd.read_csv(\n",
    "        \"/Users/louisleibovici/Documents/VS_Code/Bike_counters DSB Project/bike_counters/external_data/jours_feries_metropole.csv\",\n",
    "        date_format=\"%Y%m%d%H\"  # Ensure date format is handled correctly\n",
    "    )\n",
    "    .drop(columns=[\"annee\", \"zone\"])  # Drop unnecessary columns\n",
    ")\n",
    "\n",
    "# Convert 'date' column to datetime\n",
    "jour_feries['date'] = pd.to_datetime(jour_feries['date'])\n",
    "\n",
    "# Filter rows based on the date range of df_train and df_test\n",
    "jour_feries = jour_feries[\n",
    "    (jour_feries[\"date\"] >= df_train[\"date\"].min() - datetime.timedelta(hours=1))\n",
    "    & (jour_feries[\"date\"] <= df_test[\"date\"].max() + datetime.timedelta(hours=1))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add mouvements sociaux data :\n",
    "mouvements_sociaux = (\n",
    "    pd.read_csv(\n",
    "        \"/Users/louisleibovici/Documents/VS_Code/Bike_counters DSB Project/bike_counters/external_data/mouvements-sociaux-depuis-2002.csv\",\n",
    "        date_format=\"%Y%m%d%H\",\n",
    "        sep=\";\"\n",
    "    )\n",
    "    .drop(columns=['date_de_fin', 'Organisations syndicales', 'Métiers ciblés par le préavis',\n",
    "                   'Population devant travailler ciblee par le préavis', 'Nombre de grévistes du préavis'])  # Drop unnecessary columns\n",
    ")\n",
    "\n",
    "mouvements_sociaux['Date'] = pd.to_datetime(mouvements_sociaux['Date'])\n",
    "\n",
    "mouvements_sociaux = mouvements_sociaux[\n",
    "    (mouvements_sociaux[\"Date\"] >= df_train[\"date\"].min() - datetime.timedelta(hours=1))\n",
    "    & (mouvements_sociaux[\"Date\"] <= df_test[\"date\"].max() + datetime.timedelta(hours=1))\n",
    "]\n",
    "\n",
    "mouvements_sociaux = mouvements_sociaux[mouvements_sociaux['Date'] != pd.Timestamp('2021-03-08')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the date feature on different time scales :\n",
    "\n",
    "fr_holidays = holidays.France()\n",
    "\n",
    "def _encode_dates(X):\n",
    "    X = X.copy()  # modify a copy of X\n",
    "    # Encode the date information from the DateOfDeparture columns\n",
    "    X[\"year\"] = X[\"date\"].dt.year\n",
    "    X[\"month\"] = X[\"date\"].dt.month\n",
    "    X[\"day\"] = X[\"date\"].dt.day\n",
    "    X[\"weekday\"] = X[\"date\"].dt.weekday\n",
    "    X[\"hour\"] = X[\"date\"].dt.hour\n",
    "\n",
    "    # creation of a binary varible depicting if day in weekend\n",
    "    X[\"is_weekend\"] = np.where(X[\"weekday\"] + 1 > 5, 1, 0)\n",
    "\n",
    "    # Add a feature to indicate if the day is a holiday in France\n",
    "    X[\"is_holiday\"] = X[\"date\"].apply(lambda d: 1 if d in fr_holidays else 0)\n",
    "\n",
    "    # and if it is a jour ferie in France :\n",
    "    X[\"is_jour_ferie\"] = X[\"date\"].dt.date.isin(jour_feries['date']).astype(int)\n",
    "\n",
    "    # and it is a jour of \"mouvement social\" in France :\n",
    "    X[\"is_jour_mouvement_social\"] = X[\"date\"].dt.date.isin(mouvements_sociaux['Date']).astype(int)\n",
    "\n",
    "    # Add morning rush and evening rush features\n",
    "    # X[\"is_working_day\"] = np.where((X[\"weekday\"] + 1 <= 5), 1, 0)\n",
    "    # X[\"morning_rush\"] = (X[\"hour\"].between(7, 9)) & X[\"is_working_day\"]\n",
    "    # X[\"evening_rush\"] = (X[\"hour\"].between(17, 19)) & X[\"is_working_day\"]\n",
    "\n",
    "    # Add the season feature\n",
    "    # def season_date(date):\n",
    "      #  if (date > datetime.datetime(2020, 9, 21)) & (date < datetime.datetime(2020, 12, 21)):\n",
    "       #     return 1\n",
    "       # if (date > datetime.datetime(2020, 12, 20)) & (date < datetime.datetime(2021, 3, 20)):\n",
    "       #     return 2\n",
    "       # if (date > datetime.datetime(2021, 3, 19)) & (date < datetime.datetime(2021, 6, 21)):\n",
    "       #     return 3\n",
    "       # if ((date > datetime.datetime(2021, 6, 20)) & (date < datetime.datetime(2021, 9, 22))) | \\\n",
    "       #    ((date > datetime.datetime(2020, 6, 19)) & (date < datetime.datetime(2020, 9, 22))):\n",
    "       #     return 4\n",
    "       #  return 0  # fallback if none matches\n",
    "\n",
    "    # X[\"season\"] = X[\"date\"].apply(season_date)\n",
    "\n",
    "    return X\n",
    "\n",
    "df_train = _encode_dates(df_train)\n",
    "df_test = _encode_dates(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# To add an \"arrondissement\" feature based on latitute ande longitude\n",
    "def arrondissement(X, shapefile_path=\"/Users/louisleibovici/Documents/VS_Code/Bike_counters DSB Project/bike_counters/external_data/arrondissements.shp\"):\n",
    "\n",
    "    arrondissements = gpd.read_file(shapefile_path)\n",
    "\n",
    "    # Create a GeoDataFrame for the input dataset\n",
    "    X = X.copy()  # Work on a copy of the dataset\n",
    "    X[\"geometry\"] = X.apply(lambda row: Point(row[\"longitude\"], row[\"latitude\"]), axis=1)\n",
    "    gdf = gpd.GeoDataFrame(X, geometry=\"geometry\", crs=arrondissements.crs)\n",
    "\n",
    "    # Perform a spatial join to match points to arrondissements\n",
    "    merged = gpd.sjoin(gdf, arrondissements, how=\"left\", predicate=\"within\")\n",
    "\n",
    "    # Extract the arrondissement code (e.g., \"c_ar\") and fill missing values with 21\n",
    "    X[\"district\"] = merged[\"c_ar\"].fillna(21).astype(int)\n",
    "\n",
    "    # Drop the geometry column (optional, if not needed further)\n",
    "    X = X.drop(columns=[\"geometry\"])\n",
    "\n",
    "    return X\n",
    "\n",
    "df_train = arrondissement(df_train)\n",
    "df_test = arrondissement(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# To add covid features : one binary feature for lockdown and one binary feature for curfew periods\n",
    "def covid_features(data):\n",
    "    # Lockdown periods\n",
    "    lockdown_periods = [\n",
    "        (\"2020-10-30\", \"2020-12-15\"),\n",
    "        (\"2021-04-03\", \"2021-05-03\"),\n",
    "    ]\n",
    "\n",
    "    # Binary column for lockdown\n",
    "    data[\"is_lockdown\"] = 0\n",
    "    for start_date, end_date in lockdown_periods:\n",
    "        data.loc[\n",
    "            (data[\"date\"] >= start_date) & (data[\"date\"] < end_date),\n",
    "            \"is_lockdown\"\n",
    "        ] = 1\n",
    "\n",
    "    # Curfew periods with specific time restrictions\n",
    "    curfew_periods = [\n",
    "        (\"2020-10-17\", \"2020-10-30\", 21, 6),  # Curfew from 9 PM to 6 AM\n",
    "        (\"2020-12-16\", \"2021-01-15\", 20, 6),  # Curfew from 8 PM to 6 AM\n",
    "        (\"2021-01-15\", \"2021-03-20\", 19, 6),  # Curfew from 7 PM to 6 AM\n",
    "        (\"2021-03-20\", \"2021-04-03\", 18, 6),  # Curfew from 6 PM to 6 AM\n",
    "        (\"2021-05-03\", \"2021-06-09\", 19, 6),  # Curfew from 7 PM to 6 AM\n",
    "        (\"2021-06-09\", \"2021-06-20\", 23, 6),  # Curfew from 11 PM to 6 AM\n",
    "    ]\n",
    "\n",
    "    # Binary column for curfew\n",
    "    data[\"is_curfew\"] = 0\n",
    "    for start_date, end_date, start_hour, end_hour in curfew_periods:\n",
    "        data.loc[\n",
    "            (data[\"date\"] >= start_date) & (data[\"date\"] < end_date)\n",
    "            & ((data[\"hour\"] >= start_hour) | (data[\"hour\"] < end_hour)),\n",
    "            \"is_curfew\"\n",
    "        ] = 1\n",
    "\n",
    "    return data\n",
    "\n",
    "# Apply the function to your datasets\n",
    "df_train = covid_features(df_train)\n",
    "df_test = covid_features(df_test)\n",
    "'''\n",
    "\n",
    "# remove the date column\n",
    "df_train = df_train.drop(columns=['date'])\n",
    "df_test = df_test.drop(columns=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing :\n",
    "\n",
    "# Extract features from counter_installation_date\n",
    "for df in [df_train, df_test]:\n",
    "    df[\"installation_year\"] = df[\"counter_installation_date\"].dt.year\n",
    "    df[\"installation_month\"] = df[\"counter_installation_date\"].dt.month\n",
    "\n",
    "df_train = df_train.drop(columns=[\"counter_installation_date\"])\n",
    "df_test = df_test.drop(columns=[\"counter_installation_date\"])\n",
    "\n",
    "# Label encode high-cardinality categorical features\n",
    "label_encoders = {}\n",
    "for col in [\"counter_id\", \"site_id\", \"counter_name\", \"site_name\", \"counter_technical_id\", \"coordinates\"]:\n",
    "    le = LabelEncoder()\n",
    "    df_train[col] = le.fit_transform(df_train[col])\n",
    "    df_test[col] = le.fit_transform(df_test[col])\n",
    "    label_encoders[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=[\"bike_count\", \"log_bike_count\"])\n",
    "y_train = df_train[\"log_bike_count\"]\n",
    "\n",
    "X_test = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the XGBoost model\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "\n",
    "# Define the parameter grid for tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 6, 9, 12],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best Parameters: {'subsample': 0.8, 'n_estimators': 200, 'max_depth': 12, 'learning_rate': 0.05, 'colsample_bytree': 0.6}\n",
      "Best Score: 0.8719830285144063\n"
     ]
    }
   ],
   "source": [
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=50,  # Number of parameter settings sampled\n",
    "    scoring='neg_mean_squared_error',  # Use appropriate scoring metric\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Use all available processors\n",
    ")\n",
    "\n",
    "# Perform the search\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and score\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best Score:\", -random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the model with the best parameters\n",
    "best_xgb_model = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Preprocessing pipeline\\npipeline = Pipeline(\\n    steps=[\\n        ('preprocessor', TableVectorizer()),\\n        ('model', best_xgb_model),\\n    ]\\n)\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Preprocessing pipeline\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', TableVectorizer()),\n",
    "        ('model', best_xgb_model),\n",
    "    ]\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the XGBoost regressor\n",
    "model = best_xgb_model\n",
    "\n",
    "# Fit the model\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    ")\n",
    "\n",
    "# Make Predictions on Test Data\n",
    "y_predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36244056 1.6073475  2.1594825  ... 5.415714   4.968906   3.8987372 ]\n"
     ]
    }
   ],
   "source": [
    "print(y_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_predictions, columns=[\"log_bike_count\"]).reset_index().rename(\n",
    "    columns={\"index\": \"Id\"}\n",
    ").to_csv(\"/Users/louisleibovici/Documents/VS_Code/Bike_counters DSB Project/bike_counters/predictions_option_2_vsimple.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
