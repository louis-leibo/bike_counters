{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from skrub import TableVectorizer\n",
    "import xgboost as xgb\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import holidays\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import optuna\n",
    "\n",
    "import datetime\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the files\n",
    "df_train = pd.read_parquet(\"/Users/louisleibovici/Documents/VS_Code/Bike_counters DSB Project/bike_counters/data/train.parquet\")\n",
    "df_test = pd.read_parquet(\"/Users/louisleibovici/Documents/VS_Code/Bike_counters DSB Project/bike_counters/data/final_test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add external data : weather data\n",
    "weather = pd.read_csv(\n",
    "    \"/Users/louisleibovici/Documents/VS_Code/Bike_counters DSB Project/bike_counters/external_data/weather_data.csv.gz\",\n",
    "    parse_dates=[\"AAAAMMJJHH\"],\n",
    "    date_format=\"%Y%m%d%H\",\n",
    "    compression=\"gzip\",\n",
    "    sep=\";\",\n",
    ").rename(columns={\"AAAAMMJJHH\": \"date\"})\n",
    "\n",
    "weather = weather[\n",
    "    (weather[\"date\"] >= df_train[\"date\"].min() - datetime.timedelta(hours=1))\n",
    "    & (weather[\"date\"] <= df_test[\"date\"].max() + datetime.timedelta(hours=1))\n",
    "]\n",
    "\n",
    "weather_reduced = (\n",
    "    weather.drop(columns=[\"NUM_POSTE\", \"NOM_USUEL\", \"LAT\", \"LON\", \"QDXI3S\"])\n",
    "    .groupby(\"date\")\n",
    "    .mean()\n",
    "    .dropna(axis=1, how=\"all\")\n",
    "    .interpolate(method=\"linear\")\n",
    ")\n",
    "\n",
    "weather_reduced = (\n",
    "    weather_reduced\n",
    "    .drop(columns=[\n",
    "        \"PSTAT\", \"DD\", \"PMER\", \"PMERMIN\", \"QNEIGETOT\", \"QTCHAUSSEE\", \"ALTI\", \"QDRR1\", \"DXY\", \"FXY\",\n",
    "        \"QTNSOL\", \"QPMER\", \"DXI\", \"QFF\", \"QGLO2\", \"QGLO\", \"FF\", \"QHFXI3S\", \"QINS2\", \"QINS\",\n",
    "        \"QFXI3S\", \"RR1\", \"NEIGETOT\", 'HXI', 'HFXI3S', \"HTN\", \"HTX\", \"HUN\", \"HUX\", \"FXI3S\",\n",
    "        \"T10\", \"T20\", \"T50\", \"T100\", \"TNSOL\", \"TN50\", \"TCHAUSSEE\", \"TN\", \"TX\"\n",
    "    ])\n",
    "    .dropna(axis=1, how=\"all\")\n",
    "    .loc[:, weather_reduced.nunique(dropna=True) > 1]\n",
    "    .drop(columns=[\"QTD\", \"QTN\", \"QUN\", \"QUX\", \"QTSV\", \"QTX\", \"GLO2\", \"INS2\", \"UN\", \"UX\"])\n",
    ")\n",
    "\n",
    "# We merge :\n",
    "df_train = df_train.merge(weather_reduced, left_on=\"date\", right_on=\"date\", how=\"left\")\n",
    "df_test = df_test.merge(weather_reduced, left_on=\"date\", right_on=\"date\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add jour ferie data\n",
    "jour_feries = (\n",
    "    pd.read_csv(\n",
    "        \"/Users/louisleibovici/Documents/VS_Code/Bike_counters DSB Project/bike_counters/external_data/jours_feries_metropole.csv\",\n",
    "        date_format=\"%Y%m%d%H\"  # Ensure date format is handled correctly\n",
    "    )\n",
    "    .drop(columns=[\"annee\", \"zone\"])  # Drop unnecessary columns\n",
    ")\n",
    "\n",
    "# Convert 'date' column to datetime\n",
    "jour_feries['date'] = pd.to_datetime(jour_feries['date'])\n",
    "\n",
    "# Filter rows based on the date range of df_train and df_test\n",
    "jour_feries = jour_feries[\n",
    "    (jour_feries[\"date\"] >= df_train[\"date\"].min() - datetime.timedelta(hours=1))\n",
    "    & (jour_feries[\"date\"] <= df_test[\"date\"].max() + datetime.timedelta(hours=1))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add mouvements sociaux data :\n",
    "mouvements_sociaux = (\n",
    "    pd.read_csv(\n",
    "        \"/Users/louisleibovici/Documents/VS_Code/Bike_counters DSB Project/bike_counters/external_data/mouvements-sociaux-depuis-2002.csv\",\n",
    "        date_format=\"%Y%m%d%H\",\n",
    "        sep=\";\"\n",
    "    )\n",
    "    .drop(columns=['date_de_fin', 'Organisations syndicales', 'Métiers ciblés par le préavis',\n",
    "                   'Population devant travailler ciblee par le préavis', 'Nombre de grévistes du préavis'])  # Drop unnecessary columns\n",
    ")\n",
    "\n",
    "mouvements_sociaux['Date'] = pd.to_datetime(mouvements_sociaux['Date'])\n",
    "\n",
    "mouvements_sociaux = mouvements_sociaux[\n",
    "    (mouvements_sociaux[\"Date\"] >= df_train[\"date\"].min() - datetime.timedelta(hours=1))\n",
    "    & (mouvements_sociaux[\"Date\"] <= df_test[\"date\"].max() + datetime.timedelta(hours=1))\n",
    "]\n",
    "\n",
    "mouvements_sociaux = mouvements_sociaux[mouvements_sociaux['Date'] != pd.Timestamp('2021-03-08')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the date feature on different time scales :\n",
    "\n",
    "fr_holidays = holidays.France()\n",
    "\n",
    "def _encode_dates(X):\n",
    "    X = X.copy()  # Modify a copy of X\n",
    "\n",
    "    # Encode the date information from the DateOfDeparture columns\n",
    "    X[\"year\"] = X[\"date\"].dt.year\n",
    "    X[\"month\"] = X[\"date\"].dt.month\n",
    "    X[\"day\"] = X[\"date\"].dt.day\n",
    "    X[\"weekday\"] = X[\"date\"].dt.weekday\n",
    "    X[\"hour\"] = X[\"date\"].dt.hour\n",
    "\n",
    "    # Creation of a binary variable depicting if the day is a weekend\n",
    "    X[\"is_weekend\"] = np.where(X[\"weekday\"] + 1 > 5, 1, 0)\n",
    "\n",
    "    # Add a feature to indicate if the day is a holiday in France\n",
    "    X[\"is_holiday\"] = X[\"date\"].apply(lambda d: 1 if d in fr_holidays else 0)\n",
    "\n",
    "    # Add a feature to indicate if it is a jour férié in France\n",
    "    X[\"is_jour_ferie\"] = X[\"date\"].dt.date.isin(jour_feries[\"date\"]).astype(int)\n",
    "\n",
    "    # Add a feature to indicate if it is a jour of \"mouvement social\" in France\n",
    "    X[\"is_jour_mouvement_social\"] = X[\"date\"].dt.date.isin(mouvements_sociaux[\"Date\"]).astype(int)\n",
    "\n",
    "    # Add morning rush and evening rush features\n",
    "    X[\"is_working_day\"] = np.where((X[\"weekday\"] + 1 <= 5), 1, 0)\n",
    "    X[\"morning_rush\"] = ((X[\"hour\"].between(7, 9)) & X[\"is_working_day\"]).astype(int)\n",
    "    X[\"evening_rush\"] = ((X[\"hour\"].between(17, 19)) & X[\"is_working_day\"]).astype(int)\n",
    "\n",
    "    # Add the season feature\n",
    "    def season_date(date):\n",
    "        if (date > datetime.datetime(2020, 9, 21)) & (date < datetime.datetime(2020, 12, 21)):\n",
    "            return 1  # Autumn\n",
    "        if (date > datetime.datetime(2020, 12, 20)) & (date < datetime.datetime(2021, 3, 20)):\n",
    "            return 2  # Winter\n",
    "        if (date > datetime.datetime(2021, 3, 19)) & (date < datetime.datetime(2021, 6, 21)):\n",
    "            return 3  # Spring\n",
    "        if ((date > datetime.datetime(2021, 6, 20)) & (date < datetime.datetime(2021, 9, 22))) or \\\n",
    "           ((date > datetime.datetime(2020, 6, 19)) & (date < datetime.datetime(2020, 9, 22))):\n",
    "            return 4  # Summer\n",
    "        return 0  # Fallback if none matches\n",
    "\n",
    "    X[\"season\"] = X[\"date\"].apply(season_date)\n",
    "\n",
    "    return X\n",
    "\n",
    "df_train = _encode_dates(df_train)\n",
    "df_test = _encode_dates(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# To add an \"arrondissement\" feature based on latitute ande longitude\n",
    "def arrondissement(X, shapefile_path=\"/Users/louisleibovici/Documents/VS_Code/Bike_counters DSB Project/bike_counters/external_data/arrondissements.shp\"):\n",
    "\n",
    "    arrondissements = gpd.read_file(shapefile_path)\n",
    "\n",
    "    # Create a GeoDataFrame for the input dataset\n",
    "    X = X.copy()  # Work on a copy of the dataset\n",
    "    X[\"geometry\"] = X.apply(lambda row: Point(row[\"longitude\"], row[\"latitude\"]), axis=1)\n",
    "    gdf = gpd.GeoDataFrame(X, geometry=\"geometry\", crs=arrondissements.crs)\n",
    "\n",
    "    # Perform a spatial join to match points to arrondissements\n",
    "    merged = gpd.sjoin(gdf, arrondissements, how=\"left\", predicate=\"within\")\n",
    "\n",
    "    # Extract the arrondissement code (e.g., \"c_ar\") and fill missing values with 21\n",
    "    X[\"district\"] = merged[\"c_ar\"].fillna(21).astype(int)\n",
    "\n",
    "    # Drop the geometry column (optional, if not needed further)\n",
    "    X = X.drop(columns=[\"geometry\"])\n",
    "\n",
    "    return X\n",
    "\n",
    "df_train = arrondissement(df_train)\n",
    "df_test = arrondissement(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To add covid features : one binary feature for lockdown and one binary feature for curfew periods\n",
    "def covid_features(data):\n",
    "    # Lockdown periods\n",
    "    lockdown_periods = [\n",
    "        (\"2020-10-30\", \"2020-12-15\"),\n",
    "        (\"2021-04-03\", \"2021-05-03\"),\n",
    "    ]\n",
    "\n",
    "    # Binary column for lockdown\n",
    "    data[\"is_lockdown\"] = 0\n",
    "    for start_date, end_date in lockdown_periods:\n",
    "        data.loc[\n",
    "            (data[\"date\"] >= start_date) & (data[\"date\"] < end_date),\n",
    "            \"is_lockdown\"\n",
    "        ] = 1\n",
    "\n",
    "    # Curfew periods with specific time restrictions\n",
    "    curfew_periods = [\n",
    "        (\"2020-10-17\", \"2020-10-30\", 21, 6),  # Curfew from 9 PM to 6 AM\n",
    "        (\"2020-12-16\", \"2021-01-15\", 20, 6),  # Curfew from 8 PM to 6 AM\n",
    "        (\"2021-01-15\", \"2021-03-20\", 19, 6),  # Curfew from 7 PM to 6 AM\n",
    "        (\"2021-03-20\", \"2021-04-03\", 18, 6),  # Curfew from 6 PM to 6 AM\n",
    "        (\"2021-05-03\", \"2021-06-09\", 19, 6),  # Curfew from 7 PM to 6 AM\n",
    "        (\"2021-06-09\", \"2021-06-20\", 23, 6),  # Curfew from 11 PM to 6 AM\n",
    "    ]\n",
    "\n",
    "    # Binary column for curfew\n",
    "    data[\"is_curfew\"] = 0\n",
    "    for start_date, end_date, start_hour, end_hour in curfew_periods:\n",
    "        data.loc[\n",
    "            (data[\"date\"] >= start_date) & (data[\"date\"] < end_date)\n",
    "            & ((data[\"hour\"] >= start_hour) | (data[\"hour\"] < end_hour)),\n",
    "            \"is_curfew\"\n",
    "        ] = 1\n",
    "\n",
    "    return data\n",
    "\n",
    "# Apply the function to your datasets\n",
    "df_train = covid_features(df_train)\n",
    "df_test = covid_features(df_test)\n",
    "\n",
    "\n",
    "# remove the date column\n",
    "df_train = df_train.drop(columns=['date', 'is_working_day'])\n",
    "df_test = df_test.drop(columns=['date', 'is_working_day'])\n",
    "\n",
    "\n",
    "# remove the date column\n",
    "# df_train = df_train.drop(columns=['date'])\n",
    "# df_test = df_test.drop(columns=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns=[\"counter_id\", \"site_id\", \"counter_technical_id\", \"coordinates\"])\n",
    "df_test = df_test.drop(columns=[\"counter_id\", \"site_id\", \"counter_technical_id\", \"coordinates\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Extract features from counter_installation_date\\nfor df in [df_train, df_test]:\\n    df[\"installation_year\"] = df[\"counter_installation_date\"].dt.year\\n    df[\"installation_month\"] = df[\"counter_installation_date\"].dt.month\\n\\ndf_train = df_train.drop(columns=[\"counter_installation_date\"])\\ndf_test = df_test.drop(columns=[\"counter_installation_date\"])\\n'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Extract features from counter_installation_date\n",
    "for df in [df_train, df_test]:\n",
    "    df[\"installation_year\"] = df[\"counter_installation_date\"].dt.year\n",
    "    df[\"installation_month\"] = df[\"counter_installation_date\"].dt.month\n",
    "\n",
    "df_train = df_train.drop(columns=[\"counter_installation_date\"])\n",
    "df_test = df_test.drop(columns=[\"counter_installation_date\"])\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "counter_name                       category\n",
       "site_name                          category\n",
       "bike_count                          float64\n",
       "counter_installation_date    datetime64[us]\n",
       "latitude                            float64\n",
       "longitude                           float64\n",
       "log_bike_count                      float64\n",
       "DRR1                                float64\n",
       "HXY                                 float64\n",
       "FXI                                 float64\n",
       "T                                   float64\n",
       "QT                                  float64\n",
       "TD                                  float64\n",
       "DG                                  float64\n",
       "U                                   float64\n",
       "QU                                  float64\n",
       "DHUMI40                             float64\n",
       "DHUMI80                             float64\n",
       "TSV                                 float64\n",
       "VV                                  float64\n",
       "WW                                  float64\n",
       "GLO                                 float64\n",
       "INS                                 float64\n",
       "year                                  int32\n",
       "month                                 int32\n",
       "day                                   int32\n",
       "weekday                               int32\n",
       "hour                                  int32\n",
       "is_weekend                            int64\n",
       "is_holiday                            int64\n",
       "is_jour_ferie                         int64\n",
       "is_jour_mouvement_social              int64\n",
       "morning_rush                          int64\n",
       "evening_rush                          int64\n",
       "season                                int64\n",
       "district                              int64\n",
       "is_lockdown                           int64\n",
       "is_curfew                             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing test :\n",
    "\n",
    "ordinal_cols = [\n",
    "    \"counter_installation_date\"\n",
    "]\n",
    "\n",
    "onehot_cols = [\n",
    "    \"counter_name\",\n",
    "    \"site_name\",\n",
    "]\n",
    "\n",
    "scale_cols = [\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"year\",\n",
    "    \"month\",\n",
    "    \"day\",\n",
    "    \"weekday\",\n",
    "    \"is_weekend\",\n",
    "    \"hour\",\n",
    "    \"is_holiday\",\n",
    "    \"is_jour_ferie\",\n",
    "    \"is_jour_mouvement_social\",\n",
    "    \"morning_rush\",\n",
    "    \"evening_rush\",\n",
    "    \"season\",\n",
    "    \"district\",\n",
    "    \"is_lockdown\",\n",
    "    \"is_curfew\",\n",
    "    \"T\", \"TD\", \"DG\", \"U\", \"QU\", \"DHUMI40\", \"DHUMI80\", \"TSV\", \"VV\", \"WW\", \"GLO\", \"INS\",\n",
    "]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "onehot = OneHotEncoder(sparse_output=False)\n",
    "ordinal = OrdinalEncoder()\n",
    "\n",
    "\n",
    "# Create the preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"scale\", scaler, scale_cols),\n",
    "        (\"onehot\", onehot, onehot_cols),\n",
    "        (\"ordinal\", ordinal, ordinal_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the full pipeline\n",
    "def create_pipeline(params):\n",
    "    model = XGBRegressor(**params, random_state=42)\n",
    "    pipeline = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Preprocessing :\\n\\n# Label encode high-cardinality categorical features\\nlabel_encoders = {}\\n\\n\\nfor col in [\"counter_id\", \"site_id\", \"counter_name\", \"site_name\", \"counter_technical_id\", \"coordinates\"]:\\n    le = LabelEncoder()\\n    df_train[col] = le.fit_transform(df_train[col])\\n    df_test[col] = le.fit_transform(df_test[col])\\n    label_encoders[col] = le\\n\\n\\nfor col in [\"counter_name\", \"site_name\"]:\\n    le = LabelEncoder()\\n    df_train[col] = le.fit_transform(df_train[col])\\n    df_test[col] = le.fit_transform(df_test[col])\\n    label_encoders[col] = le\\n\\n'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Preprocessing :\n",
    "\n",
    "# Label encode high-cardinality categorical features\n",
    "label_encoders = {}\n",
    "\n",
    "\n",
    "for col in [\"counter_id\", \"site_id\", \"counter_name\", \"site_name\", \"counter_technical_id\", \"coordinates\"]:\n",
    "    le = LabelEncoder()\n",
    "    df_train[col] = le.fit_transform(df_train[col])\n",
    "    df_test[col] = le.fit_transform(df_test[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "\n",
    "for col in [\"counter_name\", \"site_name\"]:\n",
    "    le = LabelEncoder()\n",
    "    df_train[col] = le.fit_transform(df_train[col])\n",
    "    df_test[col] = le.fit_transform(df_test[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=[\"bike_count\", \"log_bike_count\"])\n",
    "y_train = df_train[\"log_bike_count\"]\n",
    "\n",
    "X_test = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the subset into train and validation sets\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-11 11:38:22,496] A new study created in memory with name: no-name-8b175eb6-34cf-4268-bbc1-cb2013ca1527\n",
      "[I 2024-12-11 11:38:25,019] Trial 0 finished with value: 0.653888518763367 and parameters: {'n_estimators': 151, 'learning_rate': 0.1226184256398182, 'max_depth': 3, 'subsample': 0.8878703030208989, 'colsample_bytree': 0.8794089618636045, 'reg_alpha': 4.440644435363952, 'reg_lambda': 3.965242289961869, 'min_child_weight': 4.611615023520662}. Best is trial 0 with value: 0.653888518763367.\n",
      "[I 2024-12-11 11:38:36,741] Trial 1 finished with value: 0.3863406960239958 and parameters: {'n_estimators': 491, 'learning_rate': 0.02965592431818022, 'max_depth': 10, 'subsample': 0.5607573217230527, 'colsample_bytree': 0.8390144011460865, 'reg_alpha': 6.031940957084063, 'reg_lambda': 9.50002177064521, 'min_child_weight': 7.825647946347612}. Best is trial 1 with value: 0.3863406960239958.\n",
      "[I 2024-12-11 11:38:41,242] Trial 2 finished with value: 0.4004098836506575 and parameters: {'n_estimators': 246, 'learning_rate': 0.11901270708307068, 'max_depth': 7, 'subsample': 0.935021640146696, 'colsample_bytree': 0.8680877403155254, 'reg_alpha': 1.5514376753404182, 'reg_lambda': 4.191484340181665, 'min_child_weight': 2.601106671626377}. Best is trial 1 with value: 0.3863406960239958.\n",
      "[I 2024-12-11 11:38:47,427] Trial 3 finished with value: 0.36703890887887064 and parameters: {'n_estimators': 350, 'learning_rate': 0.25528743476871213, 'max_depth': 7, 'subsample': 0.9918725638902618, 'colsample_bytree': 0.543130319124749, 'reg_alpha': 4.234868928142731, 'reg_lambda': 1.4249749180629443, 'min_child_weight': 3.6394675274803845}. Best is trial 3 with value: 0.36703890887887064.\n",
      "[I 2024-12-11 11:38:52,822] Trial 4 finished with value: 0.37251682949519976 and parameters: {'n_estimators': 262, 'learning_rate': 0.12584992019468158, 'max_depth': 8, 'subsample': 0.6019423049341691, 'colsample_bytree': 0.9193469027273034, 'reg_alpha': 2.9600107440999115, 'reg_lambda': 6.981793193264409, 'min_child_weight': 5.841790122737276}. Best is trial 3 with value: 0.36703890887887064.\n",
      "[I 2024-12-11 11:38:57,797] Trial 5 finished with value: 0.4562704548140041 and parameters: {'n_estimators': 392, 'learning_rate': 0.19991143457436233, 'max_depth': 4, 'subsample': 0.9028421820168311, 'colsample_bytree': 0.5507168657336481, 'reg_alpha': 9.61254921859974, 'reg_lambda': 9.365335659729485, 'min_child_weight': 7.357852686073656}. Best is trial 3 with value: 0.36703890887887064.\n",
      "[I 2024-12-11 11:39:01,428] Trial 6 finished with value: 0.5248807136626873 and parameters: {'n_estimators': 294, 'learning_rate': 0.21710559570710927, 'max_depth': 3, 'subsample': 0.5512618884351509, 'colsample_bytree': 0.8849345145147187, 'reg_alpha': 6.011980107822439, 'reg_lambda': 9.311880813143734, 'min_child_weight': 0.14837415497108675}. Best is trial 3 with value: 0.36703890887887064.\n",
      "[I 2024-12-11 11:39:03,998] Trial 7 finished with value: 0.5742429918194839 and parameters: {'n_estimators': 177, 'learning_rate': 0.11393584986855838, 'max_depth': 4, 'subsample': 0.5756263443053684, 'colsample_bytree': 0.9399857349516494, 'reg_alpha': 2.143931211448045, 'reg_lambda': 6.920918593325556, 'min_child_weight': 1.5091839423296638}. Best is trial 3 with value: 0.36703890887887064.\n",
      "[I 2024-12-11 11:39:07,195] Trial 8 finished with value: 0.6350699618756784 and parameters: {'n_estimators': 215, 'learning_rate': 0.0586654816689621, 'max_depth': 4, 'subsample': 0.5427698247804007, 'colsample_bytree': 0.5155227293920472, 'reg_alpha': 3.523492898525543, 'reg_lambda': 7.01234307045754, 'min_child_weight': 2.8506705982843106}. Best is trial 3 with value: 0.36703890887887064.\n",
      "[I 2024-12-11 11:39:12,915] Trial 9 finished with value: 0.35297013528713844 and parameters: {'n_estimators': 201, 'learning_rate': 0.29945281721141104, 'max_depth': 10, 'subsample': 0.6862185917147763, 'colsample_bytree': 0.9547051791594534, 'reg_alpha': 7.723382502474205, 'reg_lambda': 7.65852344577326, 'min_child_weight': 4.954029701063992}. Best is trial 9 with value: 0.35297013528713844.\n",
      "[I 2024-12-11 11:39:16,194] Trial 10 finished with value: 0.3710648999751625 and parameters: {'n_estimators': 108, 'learning_rate': 0.29845294411940404, 'max_depth': 10, 'subsample': 0.7326634074903471, 'colsample_bytree': 0.6982730855977437, 'reg_alpha': 8.99652208572729, 'reg_lambda': 1.1856451567207689, 'min_child_weight': 5.901800250252604}. Best is trial 9 with value: 0.35297013528713844.\n",
      "[I 2024-12-11 11:39:23,795] Trial 11 finished with value: 0.3565787597946536 and parameters: {'n_estimators': 370, 'learning_rate': 0.28233364157196805, 'max_depth': 8, 'subsample': 0.7403462835345851, 'colsample_bytree': 0.6762223927939628, 'reg_alpha': 7.119390083313064, 'reg_lambda': 0.22569183074557753, 'min_child_weight': 9.676289316274275}. Best is trial 9 with value: 0.35297013528713844.\n",
      "[I 2024-12-11 11:39:33,185] Trial 12 finished with value: 0.35189193978736616 and parameters: {'n_estimators': 379, 'learning_rate': 0.2938223841379144, 'max_depth': 9, 'subsample': 0.7260323747489921, 'colsample_bytree': 0.6945920341449825, 'reg_alpha': 7.811456151499397, 'reg_lambda': 2.8123950845529007, 'min_child_weight': 9.745594574570617}. Best is trial 12 with value: 0.35189193978736616.\n",
      "[I 2024-12-11 11:39:44,200] Trial 13 finished with value: 0.3493221902522757 and parameters: {'n_estimators': 443, 'learning_rate': 0.23730337114549183, 'max_depth': 9, 'subsample': 0.672484392419373, 'colsample_bytree': 0.7728894937923723, 'reg_alpha': 8.112076047462306, 'reg_lambda': 3.0981566414880595, 'min_child_weight': 9.203524799793195}. Best is trial 13 with value: 0.3493221902522757.\n",
      "[I 2024-12-11 11:39:55,584] Trial 14 finished with value: 0.3456852011371647 and parameters: {'n_estimators': 464, 'learning_rate': 0.2375812796258035, 'max_depth': 9, 'subsample': 0.8224128123370842, 'colsample_bytree': 0.7758454172527477, 'reg_alpha': 8.182897604926563, 'reg_lambda': 3.019864579963942, 'min_child_weight': 9.583807257385013}. Best is trial 14 with value: 0.3456852011371647.\n",
      "[I 2024-12-11 11:40:04,151] Trial 15 finished with value: 0.3698397032828058 and parameters: {'n_estimators': 498, 'learning_rate': 0.21013662873165131, 'max_depth': 6, 'subsample': 0.8243057740078319, 'colsample_bytree': 0.7776290400086893, 'reg_alpha': 8.777525078892372, 'reg_lambda': 3.12143698008822, 'min_child_weight': 8.126168491787679}. Best is trial 14 with value: 0.3456852011371647.\n",
      "[I 2024-12-11 11:40:13,703] Trial 16 finished with value: 0.35384544253913425 and parameters: {'n_estimators': 444, 'learning_rate': 0.17350932272786612, 'max_depth': 8, 'subsample': 0.6470748327846435, 'colsample_bytree': 0.782250397878985, 'reg_alpha': 6.122356263056242, 'reg_lambda': 5.1588967769433, 'min_child_weight': 8.724319588422052}. Best is trial 14 with value: 0.3456852011371647.\n",
      "[I 2024-12-11 11:40:23,536] Trial 17 finished with value: 0.3487415267008955 and parameters: {'n_estimators': 438, 'learning_rate': 0.2425091107996553, 'max_depth': 9, 'subsample': 0.8143467661353609, 'colsample_bytree': 0.598736663903944, 'reg_alpha': 0.0025258605410192203, 'reg_lambda': 5.282240423476538, 'min_child_weight': 6.806340599724447}. Best is trial 14 with value: 0.3456852011371647.\n",
      "[I 2024-12-11 11:40:30,898] Trial 18 finished with value: 0.3808641908460724 and parameters: {'n_estimators': 440, 'learning_rate': 0.16968032865248805, 'max_depth': 6, 'subsample': 0.807464043258929, 'colsample_bytree': 0.6059897843453751, 'reg_alpha': 0.49189186267864393, 'reg_lambda': 5.440668914370441, 'min_child_weight': 6.293300267397603}. Best is trial 14 with value: 0.3456852011371647.\n",
      "[I 2024-12-11 11:40:38,437] Trial 19 finished with value: 0.35152429980601835 and parameters: {'n_estimators': 323, 'learning_rate': 0.25382753676162845, 'max_depth': 9, 'subsample': 0.8296264741756474, 'colsample_bytree': 0.6274252792455914, 'reg_alpha': 0.023026966845404496, 'reg_lambda': 5.557307544163008, 'min_child_weight': 7.01140772479137}. Best is trial 14 with value: 0.3456852011371647.\n",
      "[I 2024-12-11 11:40:49,388] Trial 20 finished with value: 0.3495471566250241 and parameters: {'n_estimators': 413, 'learning_rate': 0.26127906585989785, 'max_depth': 9, 'subsample': 0.783916451600337, 'colsample_bytree': 0.6431336969337281, 'reg_alpha': 5.047430226163254, 'reg_lambda': 2.0426196861156427, 'min_child_weight': 8.799811765559218}. Best is trial 14 with value: 0.3456852011371647.\n",
      "[I 2024-12-11 11:41:01,873] Trial 21 finished with value: 0.3506680895448367 and parameters: {'n_estimators': 455, 'learning_rate': 0.2223161744575522, 'max_depth': 9, 'subsample': 0.6706401642204493, 'colsample_bytree': 0.741019188080423, 'reg_alpha': 9.867416420612848, 'reg_lambda': 4.013711387959983, 'min_child_weight': 9.146093978769986}. Best is trial 14 with value: 0.3456852011371647.\n",
      "[I 2024-12-11 11:41:12,594] Trial 22 finished with value: 0.3505408937214283 and parameters: {'n_estimators': 416, 'learning_rate': 0.2478936841993467, 'max_depth': 8, 'subsample': 0.8584394833541892, 'colsample_bytree': 0.8066267418382527, 'reg_alpha': 7.083264693692046, 'reg_lambda': 3.1101885736259036, 'min_child_weight': 9.915741743135309}. Best is trial 14 with value: 0.3456852011371647.\n",
      "[I 2024-12-11 11:41:26,062] Trial 23 finished with value: 0.344814481001642 and parameters: {'n_estimators': 467, 'learning_rate': 0.18728059015339898, 'max_depth': 10, 'subsample': 0.7704777188581644, 'colsample_bytree': 0.7370627186681002, 'reg_alpha': 8.170066173169822, 'reg_lambda': 4.576679088097775, 'min_child_weight': 6.80997428910829}. Best is trial 23 with value: 0.344814481001642.\n",
      "[I 2024-12-11 11:41:39,788] Trial 24 finished with value: 0.34340905257651017 and parameters: {'n_estimators': 474, 'learning_rate': 0.18605506420882706, 'max_depth': 10, 'subsample': 0.7726455577597438, 'colsample_bytree': 0.9972820350704241, 'reg_alpha': 6.94216373930538, 'reg_lambda': 6.121235294536779, 'min_child_weight': 7.139029059607523}. Best is trial 24 with value: 0.34340905257651017.\n",
      "[I 2024-12-11 11:41:53,560] Trial 25 finished with value: 0.3429086354963624 and parameters: {'n_estimators': 473, 'learning_rate': 0.1893433960428863, 'max_depth': 10, 'subsample': 0.7788735317004496, 'colsample_bytree': 0.9746744120492223, 'reg_alpha': 6.884386160403314, 'reg_lambda': 5.94695542288439, 'min_child_weight': 8.140511291703838}. Best is trial 25 with value: 0.3429086354963624.\n",
      "[I 2024-12-11 11:42:07,540] Trial 26 finished with value: 0.34248581645039367 and parameters: {'n_estimators': 477, 'learning_rate': 0.14877840216223456, 'max_depth': 10, 'subsample': 0.7728227340892679, 'colsample_bytree': 0.9656211101664333, 'reg_alpha': 6.79548984991269, 'reg_lambda': 6.381231359942728, 'min_child_weight': 8.014204317509872}. Best is trial 26 with value: 0.34248581645039367.\n",
      "[I 2024-12-11 11:42:23,010] Trial 27 finished with value: 0.3419420591078179 and parameters: {'n_estimators': 494, 'learning_rate': 0.14779794890073167, 'max_depth': 10, 'subsample': 0.771392944229339, 'colsample_bytree': 0.9997637479149979, 'reg_alpha': 7.016678901967515, 'reg_lambda': 6.220723488950191, 'min_child_weight': 8.076207965831005}. Best is trial 27 with value: 0.3419420591078179.\n",
      "[I 2024-12-11 11:42:38,279] Trial 28 finished with value: 0.3422873986420913 and parameters: {'n_estimators': 495, 'learning_rate': 0.14359572313764074, 'max_depth': 10, 'subsample': 0.7098073081110322, 'colsample_bytree': 0.9776533354332969, 'reg_alpha': 5.041143012258791, 'reg_lambda': 7.923460929620468, 'min_child_weight': 8.62271339156228}. Best is trial 27 with value: 0.3419420591078179.\n",
      "[I 2024-12-11 11:42:53,968] Trial 29 finished with value: 0.34761333158335517 and parameters: {'n_estimators': 500, 'learning_rate': 0.07711092770113351, 'max_depth': 10, 'subsample': 0.6270026065692287, 'colsample_bytree': 0.9027402128041968, 'reg_alpha': 5.023454803375592, 'reg_lambda': 8.194799086720874, 'min_child_weight': 4.283865288336994}. Best is trial 27 with value: 0.3419420591078179.\n",
      "[I 2024-12-11 11:43:03,913] Trial 30 finished with value: 0.3686787269460722 and parameters: {'n_estimators': 412, 'learning_rate': 0.13140312615332525, 'max_depth': 7, 'subsample': 0.7038290324603302, 'colsample_bytree': 0.990295426432084, 'reg_alpha': 4.466567577646287, 'reg_lambda': 8.50853060682152, 'min_child_weight': 7.81189869803007}. Best is trial 27 with value: 0.3419420591078179.\n",
      "[I 2024-12-11 11:43:20,165] Trial 31 finished with value: 0.34031614471474964 and parameters: {'n_estimators': 500, 'learning_rate': 0.1451613265228209, 'max_depth': 10, 'subsample': 0.8784158730880072, 'colsample_bytree': 0.969997356612937, 'reg_alpha': 6.478077838045517, 'reg_lambda': 6.305063303015271, 'min_child_weight': 8.360366846565812}. Best is trial 31 with value: 0.34031614471474964.\n",
      "[I 2024-12-11 11:43:36,728] Trial 32 finished with value: 0.3405812378719299 and parameters: {'n_estimators': 498, 'learning_rate': 0.15416287490919142, 'max_depth': 10, 'subsample': 0.8746399426430659, 'colsample_bytree': 0.9570107747429796, 'reg_alpha': 5.6758632074292334, 'reg_lambda': 6.6558944039506915, 'min_child_weight': 8.461558516198554}. Best is trial 31 with value: 0.34031614471474964.\n",
      "[I 2024-12-11 11:43:52,875] Trial 33 finished with value: 0.34418843830800366 and parameters: {'n_estimators': 499, 'learning_rate': 0.08908560161841969, 'max_depth': 10, 'subsample': 0.92740029852589, 'colsample_bytree': 0.8365617703352605, 'reg_alpha': 5.8386105225970075, 'reg_lambda': 7.601219217664951, 'min_child_weight': 8.42017458870029}. Best is trial 31 with value: 0.34031614471474964.\n",
      "[I 2024-12-11 11:44:04,734] Trial 34 finished with value: 0.34543546519024787 and parameters: {'n_estimators': 421, 'learning_rate': 0.14937072344217142, 'max_depth': 9, 'subsample': 0.9729454025856061, 'colsample_bytree': 0.9279178692235717, 'reg_alpha': 5.475889791007657, 'reg_lambda': 8.616230926179082, 'min_child_weight': 7.6558355336188}. Best is trial 31 with value: 0.34031614471474964.\n",
      "[I 2024-12-11 11:44:14,165] Trial 35 finished with value: 0.37317394188722464 and parameters: {'n_estimators': 342, 'learning_rate': 0.10376929960747912, 'max_depth': 8, 'subsample': 0.502308559913077, 'colsample_bytree': 0.8570134267731228, 'reg_alpha': 4.133252880816954, 'reg_lambda': 9.968345616705513, 'min_child_weight': 8.811134011510308}. Best is trial 31 with value: 0.34031614471474964.\n",
      "[I 2024-12-11 11:44:22,944] Trial 36 finished with value: 0.41402107297030616 and parameters: {'n_estimators': 481, 'learning_rate': 0.13731102974096412, 'max_depth': 5, 'subsample': 0.8737283471554311, 'colsample_bytree': 0.8970447208526718, 'reg_alpha': 6.423196511415578, 'reg_lambda': 7.838112356433657, 'min_child_weight': 6.3764605644710315}. Best is trial 31 with value: 0.34031614471474964.\n",
      "[I 2024-12-11 11:44:31,957] Trial 37 finished with value: 0.3455359070291972 and parameters: {'n_estimators': 273, 'learning_rate': 0.17206364410068434, 'max_depth': 10, 'subsample': 0.9085547432842459, 'colsample_bytree': 0.9456450028056586, 'reg_alpha': 5.638683126016085, 'reg_lambda': 6.707726280918342, 'min_child_weight': 7.454014384464358}. Best is trial 31 with value: 0.34031614471474964.\n",
      "[I 2024-12-11 11:44:48,282] Trial 38 finished with value: 0.43584231792024675 and parameters: {'n_estimators': 487, 'learning_rate': 0.013124074814501757, 'max_depth': 10, 'subsample': 0.9621985518825094, 'colsample_bytree': 0.9188516310413105, 'reg_alpha': 4.2710250913588474, 'reg_lambda': 7.319068900014786, 'min_child_weight': 5.513293907747574}. Best is trial 31 with value: 0.34031614471474964.\n",
      "[I 2024-12-11 11:44:59,853] Trial 39 finished with value: 0.34873733085289793 and parameters: {'n_estimators': 459, 'learning_rate': 0.15933550235178706, 'max_depth': 8, 'subsample': 0.8599154845578236, 'colsample_bytree': 0.9971589233082007, 'reg_alpha': 3.17628461794149, 'reg_lambda': 4.685509305565467, 'min_child_weight': 9.186797489913886}. Best is trial 31 with value: 0.34031614471474964.\n",
      "[I 2024-12-11 11:45:11,337] Trial 40 finished with value: 0.3532821444995375 and parameters: {'n_estimators': 392, 'learning_rate': 0.10762128534773728, 'max_depth': 9, 'subsample': 0.9437563231643653, 'colsample_bytree': 0.8647376355418402, 'reg_alpha': 5.316794679005051, 'reg_lambda': 8.945652023553967, 'min_child_weight': 8.50289668994525}. Best is trial 31 with value: 0.34031614471474964.\n",
      "[I 2024-12-11 11:45:27,402] Trial 41 finished with value: 0.343149456528826 and parameters: {'n_estimators': 480, 'learning_rate': 0.15100746769582915, 'max_depth': 10, 'subsample': 0.7111380006252598, 'colsample_bytree': 0.9671002518463138, 'reg_alpha': 6.464969603542592, 'reg_lambda': 6.383231870032865, 'min_child_weight': 7.992939367909696}. Best is trial 31 with value: 0.34031614471474964.\n",
      "[I 2024-12-11 11:45:42,095] Trial 42 finished with value: 0.34112374382124777 and parameters: {'n_estimators': 459, 'learning_rate': 0.13745341503703787, 'max_depth': 10, 'subsample': 0.8902098580181015, 'colsample_bytree': 0.9688019828021084, 'reg_alpha': 7.392511083140374, 'reg_lambda': 6.4962321833140075, 'min_child_weight': 7.564354174840723}. Best is trial 31 with value: 0.34031614471474964.\n",
      "[I 2024-12-11 11:45:57,611] Trial 43 finished with value: 0.34133406710847336 and parameters: {'n_estimators': 498, 'learning_rate': 0.12361116155685468, 'max_depth': 10, 'subsample': 0.8960102282390626, 'colsample_bytree': 0.9430700927728007, 'reg_alpha': 7.402186416957482, 'reg_lambda': 5.757125612350711, 'min_child_weight': 7.3551799301912775}. Best is trial 31 with value: 0.34031614471474964.\n",
      "[I 2024-12-11 11:46:09,285] Trial 44 finished with value: 0.3496784340453891 and parameters: {'n_estimators': 431, 'learning_rate': 0.11587242924986875, 'max_depth': 9, 'subsample': 0.8989576706807147, 'colsample_bytree': 0.9443494896868045, 'reg_alpha': 7.544791019920243, 'reg_lambda': 6.725958971879503, 'min_child_weight': 6.486316179235596}. Best is trial 31 with value: 0.34031614471474964.\n",
      "[I 2024-12-11 11:46:22,181] Trial 45 finished with value: 0.3483187708763849 and parameters: {'n_estimators': 455, 'learning_rate': 0.09044047336430042, 'max_depth': 10, 'subsample': 0.9988218921235186, 'colsample_bytree': 0.9150014983029764, 'reg_alpha': 8.745776981603141, 'reg_lambda': 5.648349143674098, 'min_child_weight': 7.396435328346373}. Best is trial 31 with value: 0.34031614471474964.\n",
      "[I 2024-12-11 11:46:24,491] Trial 46 finished with value: 0.6712111548195944 and parameters: {'n_estimators': 129, 'learning_rate': 0.12741781288181345, 'max_depth': 3, 'subsample': 0.8512631937919278, 'colsample_bytree': 0.8809821152140476, 'reg_alpha': 7.453786127741269, 'reg_lambda': 4.747862934270987, 'min_child_weight': 5.871019917973241}. Best is trial 31 with value: 0.34031614471474964.\n",
      "[I 2024-12-11 11:46:35,805] Trial 47 finished with value: 0.377883288845376 and parameters: {'n_estimators': 391, 'learning_rate': 0.05504146199450738, 'max_depth': 9, 'subsample': 0.9284388966649944, 'colsample_bytree': 0.9383405304163794, 'reg_alpha': 9.231878360248677, 'reg_lambda': 5.965384550672312, 'min_child_weight': 5.3347028552499225}. Best is trial 31 with value: 0.34031614471474964.\n",
      "[I 2024-12-11 11:46:49,974] Trial 48 finished with value: 0.34179693548337103 and parameters: {'n_estimators': 460, 'learning_rate': 0.16174985685599225, 'max_depth': 10, 'subsample': 0.8807225111834848, 'colsample_bytree': 0.8407585815820443, 'reg_alpha': 6.264488209562561, 'reg_lambda': 6.9708176322196245, 'min_child_weight': 2.0065776365830095}. Best is trial 31 with value: 0.34031614471474964.\n",
      "[I 2024-12-11 11:46:59,778] Trial 49 finished with value: 0.348951242365632 and parameters: {'n_estimators': 356, 'learning_rate': 0.16093041442715877, 'max_depth': 9, 'subsample': 0.9115259863331099, 'colsample_bytree': 0.8401773613163407, 'reg_alpha': 6.318356433584466, 'reg_lambda': 7.102007745860426, 'min_child_weight': 0.022843949175167744}. Best is trial 31 with value: 0.34031614471474964.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 500, 'learning_rate': 0.1451613265228209, 'max_depth': 10, 'subsample': 0.8784158730880072, 'colsample_bytree': 0.969997356612937, 'reg_alpha': 6.478077838045517, 'reg_lambda': 6.305063303015271, 'min_child_weight': 8.360366846565812}\n",
      "Best RMSE: 0.34031614471474964\n"
     ]
    }
   ],
   "source": [
    "# Define the Optuna objective function\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    param = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 10.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 10.0),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 1e-8, 10.0),\n",
    "    }\n",
    "\n",
    "    # Create pipeline with suggested parameters\n",
    "    pipeline = create_pipeline(param)\n",
    "\n",
    "    # Train the pipeline\n",
    "    pipeline.fit(X_train_split, y_train_split)\n",
    "\n",
    "    # Predict on validation set\n",
    "    y_pred = pipeline.predict(X_val_split)\n",
    "\n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_val_split, y_pred))\n",
    "    return rmse\n",
    "\n",
    "# Create an Optuna study and optimize\n",
    "study = optuna.create_study(direction=\"minimize\")  # Minimize RMSE\n",
    "study.optimize(objective, n_trials=50, timeout=1200)  # Adjust n_trials and timeout as needed\n",
    "\n",
    "# Get the best parameters and score\n",
    "print(\"Best Parameters:\", study.best_params)\n",
    "print(\"Best RMSE:\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the final model with the best parameters on the full dataset\n",
    "best_params = study.best_params\n",
    "final_pipeline = create_pipeline(best_params)\n",
    "final_pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# best_model = xgb.XGBRegressor(**best_params, random_state=42)\n",
    "# best_model.fit(X_train, y_train)  # Use the full training set for the final model\n",
    "\n",
    "# Predict on the test set\n",
    "# y_predictions = best_model.predict(X_test)\n",
    "y_predictions = final_pipeline.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31010622 1.5424622  1.9738607  ... 5.1187167  4.844476   3.6303234 ]\n"
     ]
    }
   ],
   "source": [
    "print(y_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_predictions, columns=[\"log_bike_count\"]).reset_index().rename(\n",
    "    columns={\"index\": \"Id\"}\n",
    ").to_csv(\"/Users/louisleibovici/Documents/VS_Code/Bike_counters DSB Project/bike_counters/predictions_XGBoost_Optuna.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
